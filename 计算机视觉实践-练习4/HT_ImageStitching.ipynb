{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423e624-f8f7-41ed-a3f9-2f1fe28c8d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goods 376\n",
      "[[[   0.         0.     ]]\n",
      "\n",
      " [[   0.       649.     ]]\n",
      "\n",
      " [[ 499.       649.     ]]\n",
      "\n",
      " [[ 499.         0.     ]]\n",
      "\n",
      " [[-378.56302 -231.372  ]]\n",
      "\n",
      " [[-604.49756  738.69977]]\n",
      "\n",
      " [[ 150.16425  648.6845 ]]\n",
      "\n",
      " [[ 253.82436   56.88591]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img1 = cv2.imread('data/map1.png')\n",
    "img2 = cv2.imread('data/map2.png')\n",
    "\n",
    "cv2.imshow('1',img1)\n",
    "cv2.imshow('2',img2)\n",
    "#img1 = cv2.resize(img1,(640,480))\n",
    "#img2 = cv2.resize(img2,(640,480))\n",
    " \n",
    "img_gray1 = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "img_gray2 = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "#创建特征检测器\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "#计算特征点和描述子\n",
    "kp1,des1 = sift.detectAndCompute(img_gray1,None)\n",
    "kp2,des2 = sift.detectAndCompute(img_gray2,None)\n",
    " \n",
    "#创建特征匹配器\n",
    "index_params = dict(algorithm=1,trees=5)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    " \n",
    "#对描述子进行特征匹配\n",
    "matches = flann.knnMatch(des1,des2,k=2) #用的knnmatch匹配\n",
    " \n",
    " \n",
    "goods = []   #选择两个匹配对象中好一些的保存下来\n",
    "for (m,n) in matches:\n",
    "    if m.distance < n.distance*0.7:\n",
    "        goods.append(m)\n",
    "         \n",
    "print('goods',len(goods))\n",
    " \n",
    "#把找到的匹配特征点保存在goods中，注意单应性矩阵要求最少4个点\n",
    "if len(goods) >= 4:\n",
    "    #把goods中的第一幅图和第二幅图的特征点坐标拿出来（坐标要float32且是三维矩阵类型  reshape(-1,1,2)） goods是Dmatch对象\n",
    "    src_points = np.float32([kp1[m.queryIdx].pt for m in goods]).reshape(-1,1,2)\n",
    "    des_points = np.float32([kp2[m.trainIdx].pt for m in goods]).reshape(-1,1,2)\n",
    "   # print('des_points:',des_points)\n",
    "     \n",
    "    #根据匹配上的关键点去计算单应性矩阵  第一个图对变成第二个图的视角计算出来的单应性矩阵\n",
    "    H,mask = cv2.findHomography(src_points,des_points,cv2.RANSAC,5) #参数5表示：允许有5个关键点的误差\n",
    "     \n",
    "#     #利用H矩阵的逆求解视角和img1特征匹配的点的img2图，并且img1没有像素\n",
    "#     warpimg = cv2.warpPerspective(img2,np.linalg.inv(H),(img1.shape[1]+img2.shape[1],img1.shape[0]+img2.shape[0]))\n",
    "#     direct = warpimg.copy()\n",
    "#     direct[0:img1.shape[0],0:img1.shape[1]] = img1 #将左边的img1的部分重新赋值\n",
    "else:\n",
    "    exit()\n",
    " \n",
    "     \n",
    "#获取原始图像的高宽\n",
    "h1,w1 = img1.shape[:2]\n",
    "h2,w2 = img2.shape[:2]\n",
    "# 获取两幅图的边界坐标\n",
    "img1_pts = np.float32([[0,0],[0,h1-1],[w1-1,h1-1],[w1-1,0]]).reshape(-1,1,2)\n",
    "img2_pts = np.float32([[0,0],[0,h2-1],[w2-1,h2-1],[w2-1,0]]).reshape(-1,1,2)\n",
    " \n",
    "#获取img1的边界坐标变换之后的坐标\n",
    "img1_transform = cv2.perspectiveTransform(img1_pts,H)\n",
    "# print('img1_pts',img1_pts)\n",
    "# print('img1_transform',img1_transform)\n",
    " \n",
    "#把img2和转换后的边界坐标连接起来\n",
    "result_pts = np.concatenate((img2_pts,img1_transform),axis=0)\n",
    "print(result_pts)\n",
    "#result_pts.min(axis=0)  #对行聚合，返回每一列的最小值\n",
    "[x_min,y_min] = np.int32(result_pts.min(axis=0).ravel()-1)\n",
    "[x_max,y_max] = np.int32(result_pts.max(axis=0).ravel()+1)\n",
    " \n",
    "#ret = cv2.drawMatchesKnn(img1,kp1,img2,kp2,[goods],None)\n",
    " \n",
    " \n",
    "#手动构造平移矩阵\n",
    "M = np.array([[1,0,-x_min],[0,1,-y_min],[0,0,1]])\n",
    "result = cv2.warpPerspective(img1,M.dot(H),(x_max-x_min,y_max-y_min))  #对img1进行平移和透视操作\n",
    " \n",
    "result[-y_min:-y_min+h2,-x_min:-x_min+w2] = img2   #把img2放进来(因为img1变换后的矩阵也平移了，所以img2也要做对应的平移)\n",
    " \n",
    "#result[0:h2,0:w2] = img2\n",
    "# cv2.imshow('direct',direct)\n",
    "# cv2.imshow('warpimg',warpimg)\n",
    "# cv2.imshow('ret',ret)\n",
    "cv2.imshow('result',result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c4c13-a699-48ce-b0c5-c1027f1e81f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TSAI",
   "language": "python",
   "name": "tsai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
